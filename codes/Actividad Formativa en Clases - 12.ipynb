{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-2433 Minería de Datos UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad en clase\n",
    "\n",
    "- Versiones de librerías, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- nltk 3.7\n",
    "- keras 2.9.0\n",
    "- tensorflow 2.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a cargar los datos del dataset de la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Son imágenes de prendas de vestuario y accesorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.axis('off')\n",
    "plt.imshow(x_train[1,])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina la clase sampling del VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina el encoder para que pase por dos capas convolucionales 2D, una capa flatten y una densa que colapsa a 32 dims. Agregue mu, var y sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 64)   640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 7, 7, 32)     18464       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1568)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           50208       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            66          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            66          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 69,444\n",
      "Trainable params: 69,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "...\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina el decoder. Tenga cuidado al dimensionar los parámetros de manera que pueda reconstruir las imágenes manteniendo las dimensiones de la entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              4704      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 128)      73856     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1153      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,209\n",
      "Trainable params: 98,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "...\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina el VAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalice las imágenes al rango [0, 1] (train_norm = x_train / 255.0). Haga lo mismo para testing. Concatene training y testing y entrene el VAE por 20 epochs con batch_size=128 y optimizador Adam. Esto se va a tardar un poco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "547/547 [==============================] - 45s 80ms/step - loss: 363.5134 - reconstruction_loss: 308.0511 - kl_loss: 5.0923\n",
      "Epoch 2/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 274.7873 - reconstruction_loss: 267.2295 - kl_loss: 5.9021\n",
      "Epoch 3/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 269.3065 - reconstruction_loss: 263.0724 - kl_loss: 5.9978\n",
      "Epoch 4/20\n",
      "547/547 [==============================] - 42s 77ms/step - loss: 267.7609 - reconstruction_loss: 261.4317 - kl_loss: 6.0155\n",
      "Epoch 5/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 267.0670 - reconstruction_loss: 260.3288 - kl_loss: 6.0437\n",
      "Epoch 6/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 265.9505 - reconstruction_loss: 259.3813 - kl_loss: 6.0650\n",
      "Epoch 7/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 265.2789 - reconstruction_loss: 258.7555 - kl_loss: 6.0830\n",
      "Epoch 8/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 265.1807 - reconstruction_loss: 258.1859 - kl_loss: 6.0921\n",
      "Epoch 9/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 263.8881 - reconstruction_loss: 257.6471 - kl_loss: 6.1131\n",
      "Epoch 10/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 263.1121 - reconstruction_loss: 257.2798 - kl_loss: 6.1369\n",
      "Epoch 11/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 262.9588 - reconstruction_loss: 256.7690 - kl_loss: 6.1249\n",
      "Epoch 12/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 262.1981 - reconstruction_loss: 256.3803 - kl_loss: 6.1504\n",
      "Epoch 13/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 262.6311 - reconstruction_loss: 256.0824 - kl_loss: 6.1531\n",
      "Epoch 14/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 261.7906 - reconstruction_loss: 255.8227 - kl_loss: 6.1857\n",
      "Epoch 15/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 261.9077 - reconstruction_loss: 255.4538 - kl_loss: 6.2057\n",
      "Epoch 16/20\n",
      "547/547 [==============================] - 43s 79ms/step - loss: 261.5987 - reconstruction_loss: 255.0972 - kl_loss: 6.2099\n",
      "Epoch 17/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 261.8292 - reconstruction_loss: 255.0141 - kl_loss: 6.2133\n",
      "Epoch 18/20\n",
      "547/547 [==============================] - 42s 77ms/step - loss: 260.8978 - reconstruction_loss: 254.7064 - kl_loss: 6.2271\n",
      "Epoch 19/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 260.6300 - reconstruction_loss: 254.4257 - kl_loss: 6.2466\n",
      "Epoch 20/20\n",
      "547/547 [==============================] - 44s 80ms/step - loss: 260.7970 - reconstruction_loss: 254.2710 - kl_loss: 6.2475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb7c16e190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_fashion = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_fashion = np.expand_dims(mnist_fashion, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina una función de data_augmentation que genere dos imágenes que correspondan a objetos distintos. Cuando las identifique, muéstrelas.\n",
    "### Use alguna función definida más arriba que le permita distinguir cuando dos imágenes son distintas. Use un umbral de error como parámetro de la función. Por ejemplo, si dos imágenes tienen un error > 500, se asume que son distintas.\n",
    "### --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def data_augmentation(umbral):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return True\n",
    "        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
