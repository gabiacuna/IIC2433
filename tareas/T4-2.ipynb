{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pontificia Universidad Cat√≥lica de Chile <br>\n",
    "Departamento de Ciencia de la Computaci√≥n <br>\n",
    "IIC2433 - Miner√≠a de Datos\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <h2> Tarea 4 </h2>\n",
    "    <h1> MLP y Regresi√≥n Log√≠stica </h1>\n",
    "    <p>\n",
    "        Profesor Marcelo Mendoza<br>\n",
    "        Segundo Semestre 2023<br>    \n",
    "        Fecha de entrega: 20 de Octubre\n",
    "    </p>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Deber√°s entregar **SOLO** el archivo .ipynb en el buz√≥n respectivo en canvas.\n",
    "\n",
    "**IMPORTANTE**:\n",
    "- Se te dar√° puntaje tanto por c√≥digo como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un c√≥digo perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendr√° el puntaje completo.\n",
    "- El notebook debe tener todas las celdas de c√≥digo ejecutadas. Cualquier notebook que no las tenga no podr√° ser corregido.\n",
    "- El car√°cter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultar√° en un 1,1 como nota de curso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n se encuentran las librer√≠as necesarias para elaborar la tarea. Recuerda ejecutar la celda antes de comenzar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from typing import List\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto: C√°ncer de mama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Octubre es dedicado como el \"Mes de la Sensibilizaci√≥n sobre el C√°ncer de Mama\". Este tipo de c√°ncer afecta a millones de personas en el mundo, y a pesar de los avances m√©dicos y campa√±as de sensibilizaci√≥n, sigue siendo una de las principales causas de muerte en mujeres.Uno de los desaf√≠os m√°s significativos es que, en muchos casos, el c√°ncer de mama no presenta s√≠ntomas evidentes en sus etapas iniciales. Esto significa que la detecci√≥n temprana a trav√©s de ex√°menes regulares y la autoexploraci√≥n mamaria son cruciales para mejorar las tasas de supervivencia y reducir la gravedad de la enfermedad en el momento del diagn√≥stico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En el √°mbito de la miner√≠a de datos, las herramientas y t√©cnicas que se ense√±an en este curso adquieren un valor excepcional en el campo de la salud, especialmente en lo que respecta a la detecci√≥n de enfermedades. La miner√≠a de datos ofrece una poderosa capacidad para analizar grandes conjuntos de informaci√≥n m√©dica, identificar patrones y tendencias ocultas, y desarrollar modelos predictivos precisos. Por lo tanto, deseamos destacar la utilidad de los conocimientos y modelos que se adquieren en este curso, ya que tienen un impacto real y significativo en la ciencia m√©dica.\n",
    "\n",
    "Gracias a la aplicaci√≥n de la miner√≠a de datos, podemos mejorar sustancialmente la eficiencia de la detecci√≥n de enfermedades. Esto significa que podemos identificar se√±ales tempranas de enfermedades, realizar diagn√≥sticos m√°s precisos y predecir la progresi√≥n de condiciones m√©dicas. En √∫ltima instancia, esta capacidad tiene el potencial de salvar vidas al permitir intervenciones m√©dicas m√°s oportunas y efectivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (3 puntos) üî•\n",
    "\n",
    "Al momento de escribir codigo es importante asegurarnos de que tanto nosotros como otras personas seran capaces de entenderlo. Con este fin, se utilizan diferentes medios como por ejemplo los comentarios al momento de implementar, docstrings para metodos, clases y modulos, type-hinting, entre otros. Debido a lo importante de esto, es que en esta tarea se otorgara un bonus de 3 puntos por el correcto uso de type-hinting al momento de declarar variables y funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Carga y Preprocesamiento de Datos (10 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta tarea, deber√°s utilizar el dataset [Breast Cancer Wisconsin](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data) que se puede encontrar en Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Carga de Datos (1 Pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data: pd.DataFrame = pd.read_csv('breast_cancer_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Descripci√≥n del Dataset (3 Pts.)\n",
    "A continuaci√≥n, presenta una descripci√≥n detallada del dataset. Se espera que investigues los datos, y expliques en que consisten al menos 9 columnas. Dentro de la explicaci√≥n, menciona a qu√© tipo de datos corresponde cada columna. ¬øCu√°l es la columna objetivo? ¬øQu√© significa cada valor de esta columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>569.0</td>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>8670.000000</td>\n",
       "      <td>869218.000000</td>\n",
       "      <td>906024.000000</td>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>9.113205e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.412729e+01</td>\n",
       "      <td>3.524049e+00</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>1.578000e+01</td>\n",
       "      <td>2.811000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.928965e+01</td>\n",
       "      <td>4.301036e+00</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>2.180000e+01</td>\n",
       "      <td>3.928000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>9.196903e+01</td>\n",
       "      <td>2.429898e+01</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>1.041000e+02</td>\n",
       "      <td>1.885000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>6.548891e+02</td>\n",
       "      <td>3.519141e+02</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>7.827000e+02</td>\n",
       "      <td>2.501000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>9.636028e-02</td>\n",
       "      <td>1.406413e-02</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>1.053000e-01</td>\n",
       "      <td>1.634000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.043410e-01</td>\n",
       "      <td>5.281276e-02</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>1.304000e-01</td>\n",
       "      <td>3.454000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>8.879932e-02</td>\n",
       "      <td>7.971981e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>1.307000e-01</td>\n",
       "      <td>4.268000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>4.891915e-02</td>\n",
       "      <td>3.880284e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>7.400000e-02</td>\n",
       "      <td>2.012000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.811619e-01</td>\n",
       "      <td>2.741428e-02</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>1.957000e-01</td>\n",
       "      <td>3.040000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>6.279761e-02</td>\n",
       "      <td>7.060363e-03</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>6.612000e-02</td>\n",
       "      <td>9.744000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>4.051721e-01</td>\n",
       "      <td>2.773127e-01</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>4.789000e-01</td>\n",
       "      <td>2.873000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853e+00</td>\n",
       "      <td>5.516484e-01</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000e+00</td>\n",
       "      <td>4.885000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059e+00</td>\n",
       "      <td>2.021855e+00</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000e+00</td>\n",
       "      <td>2.198000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>4.033708e+01</td>\n",
       "      <td>4.549101e+01</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>4.519000e+01</td>\n",
       "      <td>5.422000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>7.040979e-03</td>\n",
       "      <td>3.002518e-03</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>8.146000e-03</td>\n",
       "      <td>3.113000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.547814e-02</td>\n",
       "      <td>1.790818e-02</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>3.245000e-02</td>\n",
       "      <td>1.354000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>3.189372e-02</td>\n",
       "      <td>3.018606e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>4.205000e-02</td>\n",
       "      <td>3.960000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.179614e-02</td>\n",
       "      <td>6.170285e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>1.471000e-02</td>\n",
       "      <td>5.279000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.054230e-02</td>\n",
       "      <td>8.266372e-03</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>2.348000e-02</td>\n",
       "      <td>7.895000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>3.794904e-03</td>\n",
       "      <td>2.646071e-03</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>4.558000e-03</td>\n",
       "      <td>2.984000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.626919e+01</td>\n",
       "      <td>4.833242e+00</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>1.879000e+01</td>\n",
       "      <td>3.604000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.567722e+01</td>\n",
       "      <td>6.146258e+00</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>2.972000e+01</td>\n",
       "      <td>4.954000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.072612e+02</td>\n",
       "      <td>3.360254e+01</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>1.254000e+02</td>\n",
       "      <td>2.512000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>8.805831e+02</td>\n",
       "      <td>5.693570e+02</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1.084000e+03</td>\n",
       "      <td>4.254000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.323686e-01</td>\n",
       "      <td>2.283243e-02</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>1.460000e-01</td>\n",
       "      <td>2.226000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.542650e-01</td>\n",
       "      <td>1.573365e-01</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>3.391000e-01</td>\n",
       "      <td>1.058000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.721885e-01</td>\n",
       "      <td>2.086243e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>3.829000e-01</td>\n",
       "      <td>1.252000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.146062e-01</td>\n",
       "      <td>6.573234e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>1.614000e-01</td>\n",
       "      <td>2.910000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.900756e-01</td>\n",
       "      <td>6.186747e-02</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>3.179000e-01</td>\n",
       "      <td>6.638000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>8.394582e-02</td>\n",
       "      <td>1.806127e-02</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>9.208000e-02</td>\n",
       "      <td>2.075000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count          mean           std          min  \\\n",
       "id                       569.0  3.037183e+07  1.250206e+08  8670.000000   \n",
       "radius_mean              569.0  1.412729e+01  3.524049e+00     6.981000   \n",
       "texture_mean             569.0  1.928965e+01  4.301036e+00     9.710000   \n",
       "perimeter_mean           569.0  9.196903e+01  2.429898e+01    43.790000   \n",
       "area_mean                569.0  6.548891e+02  3.519141e+02   143.500000   \n",
       "smoothness_mean          569.0  9.636028e-02  1.406413e-02     0.052630   \n",
       "compactness_mean         569.0  1.043410e-01  5.281276e-02     0.019380   \n",
       "concavity_mean           569.0  8.879932e-02  7.971981e-02     0.000000   \n",
       "concave points_mean      569.0  4.891915e-02  3.880284e-02     0.000000   \n",
       "symmetry_mean            569.0  1.811619e-01  2.741428e-02     0.106000   \n",
       "fractal_dimension_mean   569.0  6.279761e-02  7.060363e-03     0.049960   \n",
       "radius_se                569.0  4.051721e-01  2.773127e-01     0.111500   \n",
       "texture_se               569.0  1.216853e+00  5.516484e-01     0.360200   \n",
       "perimeter_se             569.0  2.866059e+00  2.021855e+00     0.757000   \n",
       "area_se                  569.0  4.033708e+01  4.549101e+01     6.802000   \n",
       "smoothness_se            569.0  7.040979e-03  3.002518e-03     0.001713   \n",
       "compactness_se           569.0  2.547814e-02  1.790818e-02     0.002252   \n",
       "concavity_se             569.0  3.189372e-02  3.018606e-02     0.000000   \n",
       "concave points_se        569.0  1.179614e-02  6.170285e-03     0.000000   \n",
       "symmetry_se              569.0  2.054230e-02  8.266372e-03     0.007882   \n",
       "fractal_dimension_se     569.0  3.794904e-03  2.646071e-03     0.000895   \n",
       "radius_worst             569.0  1.626919e+01  4.833242e+00     7.930000   \n",
       "texture_worst            569.0  2.567722e+01  6.146258e+00    12.020000   \n",
       "perimeter_worst          569.0  1.072612e+02  3.360254e+01    50.410000   \n",
       "area_worst               569.0  8.805831e+02  5.693570e+02   185.200000   \n",
       "smoothness_worst         569.0  1.323686e-01  2.283243e-02     0.071170   \n",
       "compactness_worst        569.0  2.542650e-01  1.573365e-01     0.027290   \n",
       "concavity_worst          569.0  2.721885e-01  2.086243e-01     0.000000   \n",
       "concave points_worst     569.0  1.146062e-01  6.573234e-02     0.000000   \n",
       "symmetry_worst           569.0  2.900756e-01  6.186747e-02     0.156500   \n",
       "fractal_dimension_worst  569.0  8.394582e-02  1.806127e-02     0.055040   \n",
       "Unnamed: 32                0.0           NaN           NaN          NaN   \n",
       "\n",
       "                                   25%            50%           75%  \\\n",
       "id                       869218.000000  906024.000000  8.813129e+06   \n",
       "radius_mean                  11.700000      13.370000  1.578000e+01   \n",
       "texture_mean                 16.170000      18.840000  2.180000e+01   \n",
       "perimeter_mean               75.170000      86.240000  1.041000e+02   \n",
       "area_mean                   420.300000     551.100000  7.827000e+02   \n",
       "smoothness_mean               0.086370       0.095870  1.053000e-01   \n",
       "compactness_mean              0.064920       0.092630  1.304000e-01   \n",
       "concavity_mean                0.029560       0.061540  1.307000e-01   \n",
       "concave points_mean           0.020310       0.033500  7.400000e-02   \n",
       "symmetry_mean                 0.161900       0.179200  1.957000e-01   \n",
       "fractal_dimension_mean        0.057700       0.061540  6.612000e-02   \n",
       "radius_se                     0.232400       0.324200  4.789000e-01   \n",
       "texture_se                    0.833900       1.108000  1.474000e+00   \n",
       "perimeter_se                  1.606000       2.287000  3.357000e+00   \n",
       "area_se                      17.850000      24.530000  4.519000e+01   \n",
       "smoothness_se                 0.005169       0.006380  8.146000e-03   \n",
       "compactness_se                0.013080       0.020450  3.245000e-02   \n",
       "concavity_se                  0.015090       0.025890  4.205000e-02   \n",
       "concave points_se             0.007638       0.010930  1.471000e-02   \n",
       "symmetry_se                   0.015160       0.018730  2.348000e-02   \n",
       "fractal_dimension_se          0.002248       0.003187  4.558000e-03   \n",
       "radius_worst                 13.010000      14.970000  1.879000e+01   \n",
       "texture_worst                21.080000      25.410000  2.972000e+01   \n",
       "perimeter_worst              84.110000      97.660000  1.254000e+02   \n",
       "area_worst                  515.300000     686.500000  1.084000e+03   \n",
       "smoothness_worst              0.116600       0.131300  1.460000e-01   \n",
       "compactness_worst             0.147200       0.211900  3.391000e-01   \n",
       "concavity_worst               0.114500       0.226700  3.829000e-01   \n",
       "concave points_worst          0.064930       0.099930  1.614000e-01   \n",
       "symmetry_worst                0.250400       0.282200  3.179000e-01   \n",
       "fractal_dimension_worst       0.071460       0.080040  9.208000e-02   \n",
       "Unnamed: 32                        NaN            NaN           NaN   \n",
       "\n",
       "                                  max  \n",
       "id                       9.113205e+08  \n",
       "radius_mean              2.811000e+01  \n",
       "texture_mean             3.928000e+01  \n",
       "perimeter_mean           1.885000e+02  \n",
       "area_mean                2.501000e+03  \n",
       "smoothness_mean          1.634000e-01  \n",
       "compactness_mean         3.454000e-01  \n",
       "concavity_mean           4.268000e-01  \n",
       "concave points_mean      2.012000e-01  \n",
       "symmetry_mean            3.040000e-01  \n",
       "fractal_dimension_mean   9.744000e-02  \n",
       "radius_se                2.873000e+00  \n",
       "texture_se               4.885000e+00  \n",
       "perimeter_se             2.198000e+01  \n",
       "area_se                  5.422000e+02  \n",
       "smoothness_se            3.113000e-02  \n",
       "compactness_se           1.354000e-01  \n",
       "concavity_se             3.960000e-01  \n",
       "concave points_se        5.279000e-02  \n",
       "symmetry_se              7.895000e-02  \n",
       "fractal_dimension_se     2.984000e-02  \n",
       "radius_worst             3.604000e+01  \n",
       "texture_worst            4.954000e+01  \n",
       "perimeter_worst          2.512000e+02  \n",
       "area_worst               4.254000e+03  \n",
       "smoothness_worst         2.226000e-01  \n",
       "compactness_worst        1.058000e+00  \n",
       "concavity_worst          1.252000e+00  \n",
       "concave points_worst     2.910000e-01  \n",
       "symmetry_worst           6.638000e-01  \n",
       "fractal_dimension_worst  2.075000e-01  \n",
       "Unnamed: 32                       NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Diagnosis`: Diagnostico, *M* = Maligno, *B* = Benigno\n",
    "\n",
    "1. `radius_mean`: promedio de distancias desde el centro a puntos del per√≠metro\n",
    "2. `texture_mean`: desviaci√≥n est√°ndar de valores de escala de grises\n",
    "3. `perimeter_mean`: tama√±o del n√∫cleo\n",
    "4. `area_mean`: √°rea de la masa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Limpieza del set de datos (3 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, deber√°s revisar el dataset y hacer una limpieza de los datos. Esto significa que deber√°s tratar posibles `datos nulos, outliers, columnas innecesarias`, etc. üßê Adem√°s, es importante que utilices One Hot Encoding para el diagn√≥stico, dejando 0 a las muestras benignas y 1 a las malignas.\n",
    "\n",
    "**IMPORTANTE:** m√°s all√° del c√≥digo, lo m√°s importante aqu√≠ es `explicar` lo que est√°s haciendo, las decisiones para limpiar que tomas y sobre todo `justificar`. Hay libertad en cuanto a lo que se puede hacer, pero es **importante** que se justifique cualquier procedimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Normalizaci√≥n de datos (3 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza los datos y responde las preguntas:\n",
    "1. ¬øPor qu√© es necesario normalizar los datos?\n",
    "2. ¬øQu√© tipo de normalizaci√≥n se utiliz√≥? ¬øPor qu√©?\n",
    "3. ¬øQu√© columnas se normalizaron? ¬øPor qu√©?\n",
    "4. Explique la diferencia entre el uso de `standard scaler` y `minmax scaler` como estrategia para normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Partici√≥n training/testing (0 Pts.)\n",
    "Cree particiones de training/testing con test_size=0.3. Recuerda recuperar la variable objetivo \"y\" del dataset y `separarla` de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Perceptron y Multi Layer Perceptr√≥n (25 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Perceptron (5 Pts.)\n",
    "Investigue sobre `Perceptron`ü§ñ y de una explicaci√≥n de c√≥mo funciona. `No es necesaria una explicaci√≥n matem√°tica`, el objetivo es que puedas tomar lo que aprendiste en clases o buscando en internet, y logres exponerlo de manera sintetizada para `demostrar tu aprendizaje` üöÄ. Se espera que tu explicaci√≥n contenga la respuesta a las siguientes preguntas: ¬øQu√© es? ¬øPara qu√© sirve? ¬øC√≥mo funciona? ¬øCu√°les son sus ventajas y desventajas? ¬øEn qu√© situaciones se puede utilizar? ¬øQu√© tipo de problemas puede resolver? ¬øQu√© son los pesos y funci√≥n de activaci√≥n? ¬øCu√°les son las limitaciones del modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multi Layer Perceptron (5 Pts.)\n",
    "Ahora debes investigar sobre `Multi Layer Perceptron (MLP)` y nuevamente explicar con tus propias palabras c√≥mo funciona. Debes poner √©nfasis en las principales diferencias y cambios que tiene con respecto al `Perceptron`. Agrega en tu desarrollo la respuesta a la siguiente pregunta: ¬øPor qu√© es conveniente utilizar MLP para el dataset presentado en esta tarea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Crear y entrenar el modelo (7 Pts.)\n",
    "Entrene un clasificador de MLP con los datos de `entrenamiento`. Tienes libertad para modificar los hiperpar√°metros, cantidad de capas, neuronas, etc. Pero toda decisi√≥n debe ser `justificada`. Recuerda que el objetivo es obtener el mejor modelo posible. Para justificar tus decisiones puedes experimentar, buscar documentaci√≥n o lo que estimes conveniente.\n",
    "\n",
    "**Importante:** No se eval√∫a que el modelo sea el mejor, si no que se justifiquen las decisiones tomadas. Es decir, no sirve de nada tener un porcentaje de acierto alto si no se justifica por qu√© se lleg√≥ a ese resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluar el modelo (2 Pts.)\n",
    "Eval√∫e el modelo con los datos de `testing` y calcule `accuracy`, `precision`, `recall` y `f1-score`. Puedes apoyarte de un reporte de clasificaci√≥n. Comenta todos los resultados y explica qu√© significan üëÄ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Matriz de confusi√≥n (6 Pts.)\n",
    "Genere una `matriz de confusi√≥n` normalizada del modelo y responda las preguntas:\n",
    "1. ¬øQu√© significa cada fila de la matriz?\n",
    "2. ¬øQu√© significa cada columna de la matriz?\n",
    "3. Explique error `tipo I` y error `tipo II` en base a la matriz de confusi√≥n.\n",
    "4. En relaci√≥n al problema de c√°ncer de mama, ¬øque tipo error es m√°s grave? ¬øPor qu√©?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Regresi√≥n Log√≠stica (20 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Teor√≠a Regresi√≥n Log√≠stica (10 pts)\n",
    "Al igual que con Perceptron, investiga sobre `Regresi√≥n L√≥gistica` y da una explicaci√≥n con tus propias palabras de c√≥mo funciona. Nuevamente no se espera una demostraci√≥n matem√°tica, el objetivo es que demuestres tu aprendizaje. Puedes apoyarte de las siguientes preguntas gu√≠a: ¬øQu√© es? ¬øQu√© tipo de problemas resuelve? ¬øC√≥mo se calcula la probabilidad? ¬øQu√© funci√≥n de activaci√≥n utiliza? ¬øQu√© se busca durante el proceso de entrenamiento? ¬øQu√© son los coeficientes? ¬øC√≥mo se toma la decisi√≥n final de clasificaci√≥n? ¬øCu√°l es la relaci√≥n con la regresi√≥n lineal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Crear y entrenar el modelo (3 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea y entrena un modelo de regresion logistica con los datos de entrenamiento, donde a traves del parametro `solver`, deberas elegir minimo 3 opciones diferentes de algoritmos de optimizacion, responder `cuales son sus principales diferencias` respecto a como actualizan los parametros del modelo y `dar una hipotesis` sobre cual crees que sera el algoritmo que funcione mejor para este dataset. Recuerda que la idea es que `justifiques tu respuesta`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluar el modelo (2 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para `cada uno` de los tres modelos anteriores, evalua el modelo con los datos de testing y calcula `accuracy`, `precision`, `recall` y `f1-score`. Puedes apoyarte de un reporte de clasificaci√≥n. Comenta todos los resultados y explica qu√© significan üëÄ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Matriz de confusi√≥n (5 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los modelos elegidos previamente, escoja el que mejor funcione y genere una `matriz de confusi√≥n` del modelo y responda la siguiente pregunta:\n",
    "\n",
    "1. ¬øQue tan grave es el error que tenemos segun la matriz de confusi√≥n en el problema de c√°ncer de mama? ¬øPor qu√©?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Comparaci√≥n de Modelos (5 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comparaci√≥n de modelos (5 Pts.)\n",
    "Una vez implementado cada modelo con los datos, compara los resultados obtenidos.\n",
    "1. ¬øQue modelo posee el mejor `rendimiento` en este caso? ¬øPor qu√©?\n",
    "2. ¬øQu√© m√©tricas se utilizaron para comparar los modelos?\n",
    "3. ¬øQu√© ventajas y desventajas tiene cada modelo?\n",
    "4. ¬øEn que casos es mejor utilizar un modelo que otro? ¬øPor qu√©?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
