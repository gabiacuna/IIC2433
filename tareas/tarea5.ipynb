{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3B6kdIC0A8j"
      },
      "source": [
        "Pontificia Universidad Católica de Chile <br>\n",
        "Departamento de Ciencia de la Computación <br>\n",
        "IIC2433 - Minería de Datos\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "    <h2> Tarea 5 </h2>\n",
        "    <h1> SVM </h1>\n",
        "    <p>\n",
        "        Profesor Marcelo Mendoza<br>\n",
        "        Segundo Semestre 2023<br> \n",
        "        Fecha de entrega: 3 de noviembre\n",
        "    </p>\n",
        "    <br>\n",
        "</center>\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx4hXVuL2Lv-"
      },
      "source": [
        "## Indicaciones\n",
        "\n",
        "Deberás entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas.\n",
        "\n",
        "**IMPORTANTE**:\n",
        "- Se te dará puntaje tanto por código como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un código perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendrá el puntaje completo.\n",
        "- El notebook debe tener todas las celdas de código ejecutadas. Cualquier notebook que no las tenga no podrá ser corregido.\n",
        "- El carácter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultará en un 1,1 como nota de curso.\n",
        "- En el caso de que se encuentren con problemas al correr celdas por el tamaño del dataset, esta permitido trabajar con una muestra representativa de este, siempre explicitando y justificando sus deciciones.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D20JLCp2NQy"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jxFL6JoZ2k9D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Gabi\\Documents\\U-2023-2\\IIC2433\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "##Importa acá las librerias que vayas a utilizar\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contexto:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se tiene un dataset con información de distintas noticias, entre las cuales hay noticias falsas y verdaderas. El objetivo de esta tarea es predecir si una noticia es falsa o verdadera, utilizando distintos modelos de clasificación.. Para esto, primero se debe hacer un análisis exploratorio de los datos para decidir qué variables son relevantes para el problema. Luego, se debe vectorizar el texto de loas noticias para poder utilizarlo en un modelo de clasificación (en esta tarea usaremos SBert y TF-IDF). Después se debe entrenar un modelo de clasificación SVM que prediga si una noticia es falsa o verdadera. Finalmente, se debe evaluar el modelo y compararlo con otros modelos de clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objetivos de la tarea:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Realizar un análisis exploratorio de datos para determinar las variables pertinentes para el problema en cuestión, identificando características clave y patrones en los datos que podrían afectar la clasificación de las noticias.\n",
        "- Dominar la técnica de vectorización de texto para facilitar su aplicación en un modelo de clasificación, y comprender la interpretación de los resultados obtenidos.\n",
        "- Entender el funcionamiento de un modelo de clasificación SVM y sus hiperparámetros.\n",
        "- Entrenar un modelo de clasificación SVM capaz de predecir si una noticia es falsa o verdadera.\n",
        "- Evaluar el desempeño del modelo y analizar en profundidad los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAwvXdDO36uO"
      },
      "source": [
        "# Parte 1: Carga y Preprocesamiento (10 puntos)\n",
        "\n",
        "## 1.1 Carga de datos (1 punto)\n",
        "\n",
        "Para esta tarea deberás trabajar con el dataset que está en Canvas, 'news.csv'. Este dataset contiene información de distintas noticias, entre las cuales hay noticias falsas y verdaderas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
              "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
              "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
              "\n",
              "                                                text subject  \\\n",
              "0  Donald Trump just couldn t wish all Americans ...    News   \n",
              "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
              "2  On Friday, it was revealed that former Milwauk...    News   \n",
              "3  On Christmas day, Donald Trump announced that ...    News   \n",
              "4  Pope Francis used his annual Christmas Day mes...    News   \n",
              "\n",
              "                date authenticity  \n",
              "0  December 31, 2017         Fake  \n",
              "1  December 31, 2017         Fake  \n",
              "2  December 30, 2017         Fake  \n",
              "3  December 29, 2017         Fake  \n",
              "4  December 25, 2017         Fake  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('news.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjqBcwhUGa2j"
      },
      "source": [
        "## 1.2 Descripcion del Dataset (5 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2893"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data.iloc[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptkeso4_NZbp"
      },
      "source": [
        "¿Qué representa cada feature en el dataset entregado? Refiérete a su tipo de dato, detallando cómo trabajar con los datos no númericos (2 puntos)\n",
        "\n",
        "RESPUESTA:\n",
        "\n",
        "- title : Título de la noticia\n",
        "- text : Cuerpo de la noticia\n",
        "- subject : Tema de la noticia\n",
        "- date : Fecha de publicación de la noticia\n",
        "- authenticity : Variable objetivo, indica si la noticia es falsa o verdadera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JSFOZ7lRzA5"
      },
      "source": [
        "¿Qué columnas o features crees son relevantes para el problema? ¿Por qué? (3 puntos)\n",
        "\n",
        "RESPUESTA:  \n",
        "El cuerpo, ya que se cuenta con una mayor cantidad de palabras que los títulos. Además, el título puede ser engañoso, por lo que el cuerpo de la noticia es más relevante para determinar si es falsa o verdadera. El tema tambien considero que puede ser relevante ya que puede haber temas que sean más propensos a tener noticias falsas o verdaderas, en el caso de este dataset, solo se cuenta con 2 tipos por lo que no creo que sea tan relevante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeCYvsCyRXUU"
      },
      "source": [
        "## 1.3 Datos nulos (2 puntos)\n",
        "\n",
        "Analiza la presencia de valores nulos en el conjunto de datos y cómo se distribuyen en las distintas columnas. Después, toma una decisión acerca del tratamiento adecuado para el dataframe con respecto a los valores nulos. Justifica tu decisión.\n",
        "\n",
        "RESPUESTA:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "title           0\n",
              "text            0\n",
              "subject         0\n",
              "date            0\n",
              "authenticity    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "title           9954\n",
              "text            9962\n",
              "subject            2\n",
              "date             787\n",
              "authenticity       2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede ver que no hay valores nulos en el dataset, por lo que no es necesario realizar un tratamiento de valores nulos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhm6ZjBnRix7"
      },
      "source": [
        "## 1.4 Manejo del Dataset (2 puntos)\n",
        "\n",
        "- Elimina las columnas que no sean relevantes para el entrenamiento del modelo (1 pts.)\n",
        "- Haz que los textos estén en un formato óptimo para ser procesados por los modelos de clasificación (0.5 pts.) Justifica tu decisión (0.5 pts.)\n",
        "\n",
        "\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = data['authenticity']\n",
        "X = data.drop(['authenticity'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para que los textos esten en un formato optimo, se puede utilizar la libreria NLTK para eliminar stopwords y lematizar las palabras. Además, se puede utilizar la libreria re para eliminar caracteres especiales y numeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Gabi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Gabi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def no_stop_words(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    return \" \".join(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_ = X.copy()\n",
        "X_['title'] = X_['title'].apply(no_stop_words)\n",
        "X_['text'] = X['text'].apply(no_stop_words)\n",
        "X_ = X_.drop(['date', 'subject'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 2: Vectorización (14 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SBert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte, deben utilizar SBert para vectorizar los textos de las noticias. Utilicen el modelo pre-entrenado de SBert llamado SentenceTransformer. Específicamente, deben usar el modelo 'paraphrase-MiniLM-L6-v2' para obtener las representaciones vectoriales de las oraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1) Vectorización con SBert (3 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = X_['text'].to_list()\n",
        "\n",
        "#Sentences are encoded by calling model.encode()\n",
        "SBert_texts = model.encode(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2) Análisis teórico de SBert (4 puntos)\n",
        "Responde las siguientes preguntas: ¿Qué es SBert? ¿Cómo funciona? ¿Qué ventajas y desventajas tiene sobre otros modelos de vectorización de texto?\n",
        "\n",
        "RESPUESTA:\n",
        "\n",
        "SBert, Sentence BERT, es una técnica de vectorización de texto que utiliza un modelo pre-entrenado para obtener representaciones vectoriales de oraciones. Para esto, se utiliza un modelo pre-entrenado de BERT (Bidirectional Encoder Representations from Transformers), que es un modelo de lenguaje que utiliza una arquitectura de Transformer. Con este se obtienen representaciones vectoriales de oraciones, en vez de palabras. Primero se utiliza el modelo pre-entrenado BERT para las representaciones vectoriales de palabras y luego se utiliza un modelo de pooling promedio para obtener una representación vectorial de la oración, promediando los vectores de las palabras de la oración.\n",
        "\n",
        "Ventajas:\n",
        "- Mejora la captura de la semántica de las oraciones.\n",
        "- Reduce la necesidad de entrenamiento ya que utiliza un modelo pre-entrenado.\n",
        "\n",
        "Desventajas:\n",
        "- Al utilizar un modelo basado en transformers, puede ser computacionalmente costoso.\n",
        "- Necesita Ajuste y Finetuning para obtener mejores resultados.\n",
        "\n",
        "fuentes:   \n",
        "https://arxiv.org/abs/1908.10084  \n",
        "https://medium.com/mlearning-ai/semantic-search-with-s-bert-is-all-you-need-951bc710e160  \n",
        "https://towardsdatascience.com/an-intuitive-explanation-of-sentence-bert-1984d144a868\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte, deben utilizar TF-IDF para vectorizar los textos de las noticias. Utilicen la clase TfidfVectorizer de la librería sklearn.\n",
        "\n",
        "\n",
        "Tip: limita la cantidad de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3) Vectorización con TF-IDF (3 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "max_features = 100\n",
        "vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "TfIdf_texts = vectorizer.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2) Análisis teórico de TF-IDF (4 puntos)\n",
        "Responde las siguientes preguntas: ¿Qué es TF-IDF? ¿Cómo funciona? ¿Qué ventajas y desventajas tiene sobre otros modelos de vectorización de texto?\n",
        "\n",
        "RESPUESTA:\n",
        "\n",
        "Literalmente significa *Term frecuency - Inverse document fercuency*, lo que quiere decir la frecuencia de ocurrencia del término en el documento. Es una medida estadística que se utiliza para evaluar la importancia de una palabra en un documento. Se considera que a mayor frecuencia de una palabra, más importancia tiene en el documento. \n",
        "\n",
        "La ventaja de este modelo es que es simple de implementar y es muy eficiente computacionalmente. Una desventaja es que no considera la semántica de las palabras, por lo que puede haber palabras que tengan un alto TF-IDF pero que no sean relevantes para el documento, por eso es importante quitar las 'stop words' antes de realizar una analisis.\n",
        "\n",
        "En cuanto a otros modelos de vectorización, se puede decir que es más simple de implementar que SBert, pero no considera la semántica de las palabras, lo que si realiza SBert.\n",
        "\n",
        "fuentes:  \n",
        "https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/  \n",
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVspTAuVGsUM"
      },
      "source": [
        "# Parte 3: SVM (36 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1) Preguntas teóricas (10 puntos)\n",
        "1. ¿Qué es SVM? ¿Cómo funciona? ¿En qué casos es útil? ¿En cuáles no? (4 ptos.)  \n",
        "    Una *Support-Vector Machine*, o maquina de vectores de soporte, es un tipo de algoritmo de aprendizaje supervisado que puede ser utilizado para clasificación o regresión. La idea es generar un hiperplano separador que maximice la distancia entre los puntos de datos de las clases (para clasificación).\n",
        "\n",
        "    Busca el hiperplano maximizando el margen entre las clases. Los puntos mas cercanos al hiperplano son los vectores de soporte, y en base a ellos se clasifican nuevos puntos.\n",
        "\n",
        "    Son útiles cuando el conjunto de datos tiene múltiples caracteristicas y la separación entre clases es clara. No son útiles cuando el conjunto de datos tiene muchas caracteristicas y la separación entre clases no es clara.\n",
        "    \n",
        "3. ¿Qué es un kernel? ¿Qué tipos de kernels existen? ¿Cuál es la diferencia entre ellos? (3 ptos.)  \n",
        "    Un kernel en este contexto es una función que toma datos de entrada de baja dimensionalidad y los transforma en datos de alta dimensionalidad. Existen distintos tipos de kernels, como el kernel lineal, polinomial, gaussiano, etc. La diferencia entre ellos es la función que utilizan para transformar los datos de entrada. Cada kernel realiza una transformación diferente sobre los datos.\n",
        "\n",
        "4. ¿Qué indica el parámetro C? ¿Qué sucede si C es muy grande? ¿Y si es muy pequeño? (3 ptos.)  \n",
        "    Es el parametro de regularización, que controla el equilibrio entre maximizar el margen y minimizar la clasificación incorrecta. Si C es muy grande, se penaliza mucho la clasificación incorrecta, por lo que se puede generar un sobreajuste. Si C es muy pequeño, se penaliza poco la clasificación incorrecta, por lo que se puede generar un subajuste.\n",
        "\n",
        "fuentes:  \n",
        "https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/  \n",
        "https://scikit-learn.org/stable/modules/svm.html  \n",
        "https://www.geeksforgeeks.org/introduction-to-support-vector-machines-svm/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2) SVM con vectorización SBert (10 puntos) \n",
        "Para esta parte deben entrenar un modelo SVM con las representaciones vectoriales obtenidas con SBert. Deben utilizar la clase SVC de la librería sklearn. Para esto:\n",
        "- Deben dejar los datos en un formato adecuado para ser procesados por el modelo (1 pto.)\n",
        "- Dividir el dataset en train y test (1 pto.)\n",
        "- Entrenar el modelo SVM con los datos de train (2 ptos.) modificando los hiperparámetros kernel y C (4 ptos.)\n",
        "- Evaluar el modelo con los datos de test y comentar brevemente los resultados obtenidos (2 ptos.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(SBert_texts, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: linear, C: 0.1\n",
            "accuracy: 0.9915\n",
            "Kernel: linear, C: 1\n",
            "accuracy: 0.9895\n",
            "Kernel: linear, C: 10\n",
            "accuracy: 0.985\n",
            "Kernel: poly, C: 0.1\n",
            "Degree: 2\n",
            "accuracy: 0.965\n",
            "Degree: 3\n",
            "accuracy: 0.942\n",
            "Degree: 4\n",
            "accuracy: 0.9115\n",
            "Degree: 5\n",
            "accuracy: 0.8645\n",
            "Degree: 6\n",
            "accuracy: 0.827\n",
            "Kernel: poly, C: 1\n",
            "Degree: 2\n",
            "accuracy: 0.989\n",
            "Degree: 3\n",
            "accuracy: 0.985\n",
            "Degree: 4\n",
            "accuracy: 0.981\n",
            "Degree: 5\n",
            "accuracy: 0.966\n",
            "Degree: 6\n",
            "accuracy: 0.9455\n",
            "Kernel: poly, C: 10\n",
            "Degree: 2\n",
            "accuracy: 0.9885\n",
            "Degree: 3\n",
            "accuracy: 0.984\n",
            "Degree: 4\n",
            "accuracy: 0.982\n",
            "Degree: 5\n",
            "accuracy: 0.977\n",
            "Degree: 6\n",
            "accuracy: 0.9655\n",
            "Kernel: rbf, C: 0.1\n",
            "accuracy: 0.9635\n",
            "Kernel: rbf, C: 1\n",
            "accuracy: 0.9875\n",
            "Kernel: rbf, C: 10\n",
            "accuracy: 0.9895\n",
            "Kernel: sigmoid, C: 0.1\n",
            "accuracy: 0.9685\n",
            "Kernel: sigmoid, C: 1\n",
            "accuracy: 0.96\n",
            "Kernel: sigmoid, C: 10\n",
            "accuracy: 0.936\n"
          ]
        }
      ],
      "source": [
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "C = [0.1, 1, 10] #, 100, 1000]\n",
        "degrees = [2, 3, 4, 5, 6]\n",
        "clfs = {}\n",
        "\n",
        "for kernel in kernels:\n",
        "    for c in C:\n",
        "        print(f\"Kernel: {kernel}, C: {c}\")\n",
        "        if kernel == 'poly':\n",
        "            for degree in degrees:\n",
        "                print(f\"Degree: {degree}\")\n",
        "                clf = SVC(kernel=kernel, C=c, degree=degree)\n",
        "                clf.fit(X_train, y_train)\n",
        "                clfs[(kernel, c, degree)] = clf\n",
        "                accuracy = clf.score(X_test, y_test)\n",
        "                print(f'accuracy: {accuracy}')\n",
        "        else:\n",
        "            clf = SVC(kernel=kernel, C=c)\n",
        "            clf.fit(X_train, y_train)\n",
        "            clfs[(kernel, c, 0)] = clf\n",
        "            accuracy = clf.score(X_test, y_test)\n",
        "            print(f'accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Luego de analizar el outout completo, se puede notar que la mayor accuracy, fue obtenida por el kernel lineal con C=1, con un valor de 0.9895. Esto me sorprendio ya que asumí que los datos de texto no se ajustarian correctamente a un separador lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys([('linear', 0.1, 0), ('linear', 1, 0), ('linear', 10, 0), ('poly', 0.1, 2), ('poly', 0.1, 3), ('poly', 0.1, 4), ('poly', 0.1, 5), ('poly', 0.1, 6), ('poly', 1, 2), ('poly', 1, 3), ('poly', 1, 4), ('poly', 1, 5), ('poly', 1, 6), ('poly', 10, 2), ('poly', 10, 3), ('poly', 10, 4), ('poly', 10, 5), ('poly', 10, 6), ('rbf', 0.1, 0), ('rbf', 1, 0), ('rbf', 10, 0), ('sigmoid', 0.1, 0), ('sigmoid', 1, 0), ('sigmoid', 10, 0)])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfs.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3) SVM con vectorización TF-IDF (10 puntos) \n",
        "Para esta parte deben entrenar un modelo SVM con las representaciones vectoriales obtenidas con TF-IDF. Deben utilizar la clase SVC de la librería sklearn. Para esto:\n",
        "- Deben dejar los datos en un formato adecuado para ser procesados por el modelo (1 pto.)\n",
        "- Dividir el dataset en train y test (1 pto.)\n",
        "- Entrenar el modelo SVM con los datos de train (2 ptos.) modificando los hiperparámetros kernel y C (4 ptos.)\n",
        "- Evaluar el modelo con los datos de test y comentar brevemente los resultados obtenidos (2 ptos.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4) Análisis de resultados (6 puntos)\n",
        "- ¿Qué vectorización obtuvo mejores resultados, SBert o TF-IDF? ¿Por qué? (3 ptos.)\n",
        "- ¿Qué hiperparámetros obtuvieron mejores resultados para cada vectorización? (3 ptos.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 4 (Bonus): LIME explainer (5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación haz un análisis de los resultados obtenidos con el modelo SVM con vectorización SBert utilizando LIME explainer. Para esto, debes seguir los siguientes pasos:\n",
        "- Instalar la librería Lime\n",
        "- Elegir un ejemplo de test\n",
        "- Utilizar el explainer de Lime para explicar la predicción del modelo en ese ejemplo (2.5 pts.)\n",
        "- Analizar los resultados obtenidos y comentar brevemente (2.5 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
